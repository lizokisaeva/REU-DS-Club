# -*- coding: utf-8 -*-
"""Итоговый проект.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13LdwTRsYM6_Gac7dT5mHNhHKEGxrH3OC

# Первая часть. Исследование
"""

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings(action='ignore', category=DeprecationWarning)

"""## Загрузка данных

Итоговый проект посвящен классификации оттока клиентов телеком-компании. Датасет взят из соревнования Kaggle: https://www.kaggle.com/competitions/advanced-dls-spring-2021/overview/description.
"""

from google.colab import drive
drive.mount('/content/drive')

data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/REU DS Club/Итоговый проект/train.csv')
test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/REU DS Club/Итоговый проект/test.csv')
sample_submission = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/REU DS Club/Итоговый проект/submission.csv')
test.sample(5)

"""Проверим, есть ли пропущенные значения в датасете."""

pd.DataFrame(data.isnull().sum())

data.info()

test.info()

"""Разобьем первоначальные данные на категориальные и численные для удобства."""

# Числовые признаки
num_cols = [
    'ClientPeriod',
    'MonthlySpending',
    'TotalSpent'
]

# Категориальные признаки
cat_cols = [
    'Sex',
    'IsSeniorCitizen',
    'HasPartner',
    'HasChild',
    'HasPhoneService',
    'HasMultiplePhoneNumbers',
    'HasInternetService',
    'HasOnlineSecurityService',
    'HasOnlineBackup',
    'HasDeviceProtection',
    'HasTechSupportAccess',
    'HasOnlineTV',
    'HasMovieSubscription',
    'HasContractPhone',
    'IsBillingPaperless',
    'PaymentMethod'
]

feature_cols = num_cols + cat_cols
target_col = 'Churn'

"""Поправим значения в колонке TotalSpent."""

spaces = []
for idx, i in enumerate(data['TotalSpent']):
    if i == ' ':
        spaces.append(idx)
data.drop(labels=spaces, axis=0, inplace=True)
data.reset_index(drop=True, inplace=True)

test.loc[test['TotalSpent'] == ' ', 'TotalSpent'] = -1

data['TotalSpent'] = data['TotalSpent'].astype(float)
test['TotalSpent'] = test['TotalSpent'].astype(float)

data.info()

test.info()

"""## Анализ данных

Посмотрим на распределения признаков: для численных - гистограммы, для категориальных - количество каждого значения для каждого признака.
"""

for col in num_cols:
    plt.hist(data[col], bins=20)
    plt.xlabel(col)
    plt.show()

for col in cat_cols:
    x = data[col].value_counts()
    plt.bar(x.index, x.values)
    plt.xlabel(col)
    plt.xticks(data[col].value_counts().index, rotation=45)
    plt.show()

"""Посмотрим на распределение целевой переменной."""

plt.bar(data[target_col].value_counts().index, data[target_col].value_counts().values)
plt.xlabel(target_col)
plt.xticks(data[target_col].value_counts().index)
plt.show()

"""Классы очень несбалансированы, значение "0" в 2.5 раза превышает значение "1". В связи с этим применять метрику Accuracy не будем.

Для того чтобы проверить распределение признаков, посмотрим на ящики с усами (boxplot).
"""

data.boxplot(figsize=(10,5))

"""Выбросы в данных отсутствуют.

Переведем некоторые категориальные признаки в бинарную систему для удобства применения различных моделей машинного обучения.
"""

data['Sex'] = np.where(data['Sex']=='Male', 1, 0)
data['HasPartner'] = np.where(data['HasPartner']=='Yes', 1, 0)
data['HasChild'] = np.where(data['HasChild']=='Yes', 1, 0)
data['HasPhoneService'] = np.where(data['HasPhoneService']=='Yes', 1, 0)
data['IsBillingPaperless'] = np.where(data['IsBillingPaperless']=='Yes', 1, 0)

test['Sex'] = np.where(test['Sex']=='Male', 1, 0)
test['HasPartner'] = np.where(test['HasPartner']=='Yes', 1, 0)
test['HasChild'] = np.where(test['HasChild']=='Yes', 1, 0)
test['HasPhoneService'] = np.where(test['HasPhoneService']=='Yes', 1, 0)
test['IsBillingPaperless'] = np.where(test['IsBillingPaperless']=='Yes', 1, 0)

data.loc[data['HasMultiplePhoneNumbers'] == 'Yes', 'HasMultiplePhoneNumbers'] = 1
data.loc[data['HasMultiplePhoneNumbers'] == 'No', 'HasMultiplePhoneNumbers'] = 0
data.loc[data['HasMultiplePhoneNumbers'] == 'No phone service', 'HasMultiplePhoneNumbers'] = -1
data['HasMultiplePhoneNumbers'] = data['HasMultiplePhoneNumbers'].astype(int)

data.loc[data['HasInternetService'] == 'Fiber optic', 'HasInternetService'] = 1
data.loc[data['HasInternetService'] == 'No', 'HasInternetService'] = 0
data.loc[data['HasInternetService'] == 'DSL', 'HasInternetService'] = -1
data['HasInternetService'] = data['HasInternetService'].astype(int)

data.loc[data['HasOnlineSecurityService'] == 'Yes', 'HasOnlineSecurityService'] = 1
data.loc[data['HasOnlineSecurityService'] == 'No', 'HasOnlineSecurityService'] = 0
data.loc[data['HasOnlineSecurityService'] == 'No internet service', 'HasOnlineSecurityService'] = -1
data['HasOnlineSecurityService'] = data['HasOnlineSecurityService'].astype(int)

data.loc[data['HasOnlineBackup'] == 'Yes', 'HasOnlineBackup'] = 1
data.loc[data['HasOnlineBackup'] == 'No', 'HasOnlineBackup'] = 0
data.loc[data['HasOnlineBackup'] == 'No internet service', 'HasOnlineBackup'] = -1
data['HasOnlineBackup'] = data['HasOnlineBackup'].astype(int)

data.loc[data['HasDeviceProtection'] == 'Yes', 'HasDeviceProtection'] = 1
data.loc[data['HasDeviceProtection'] == 'No', 'HasDeviceProtection'] = 0
data.loc[data['HasDeviceProtection'] == 'No internet service', 'HasDeviceProtection'] = -1
data['HasDeviceProtection'] = data['HasDeviceProtection'].astype(int)

data.loc[data['HasTechSupportAccess'] == 'Yes', 'HasTechSupportAccess'] = 1
data.loc[data['HasTechSupportAccess'] == 'No', 'HasTechSupportAccess'] = 0
data.loc[data['HasTechSupportAccess'] == 'No internet service', 'HasTechSupportAccess'] = -1
data['HasTechSupportAccess'] = data['HasTechSupportAccess'].astype(int)

data.loc[data['HasOnlineTV'] == 'Yes', 'HasOnlineTV'] = 1
data.loc[data['HasOnlineTV'] == 'No', 'HasOnlineTV'] = 0
data.loc[data['HasOnlineTV'] == 'No internet service', 'HasOnlineTV'] = -1
data['HasOnlineTV'] = data['HasOnlineTV'].astype(int)

data.loc[data['HasMovieSubscription'] == 'Yes', 'HasMovieSubscription'] = 1
data.loc[data['HasMovieSubscription'] == 'No', 'HasMovieSubscription'] = 0
data.loc[data['HasMovieSubscription'] == 'No internet service', 'HasMovieSubscription'] = -1
data['HasMovieSubscription'] = data['HasMovieSubscription'].astype(int)

test.loc[test['HasMultiplePhoneNumbers'] == 'Yes', 'HasMultiplePhoneNumbers'] = 1
test.loc[test['HasMultiplePhoneNumbers'] == 'No', 'HasMultiplePhoneNumbers'] = 0
test.loc[test['HasMultiplePhoneNumbers'] == 'No phone service', 'HasMultiplePhoneNumbers'] = -1
test['HasMultiplePhoneNumbers'] = test['HasMultiplePhoneNumbers'].astype(int)

test.loc[test['HasInternetService'] == 'Fiber optic', 'HasInternetService'] = 1
test.loc[test['HasInternetService'] == 'No', 'HasInternetService'] = 0
test.loc[test['HasInternetService'] == 'DSL', 'HasInternetService'] = -1
test['HasInternetService'] = test['HasInternetService'].astype(int)

test.loc[test['HasOnlineSecurityService'] == 'Yes', 'HasOnlineSecurityService'] = 1
test.loc[test['HasOnlineSecurityService'] == 'No', 'HasOnlineSecurityService'] = 0
test.loc[test['HasOnlineSecurityService'] == 'No internet service', 'HasOnlineSecurityService'] = -1
test['HasOnlineSecurityService'] = test['HasOnlineSecurityService'].astype(int)

test.loc[test['HasOnlineBackup'] == 'Yes', 'HasOnlineBackup'] = 1
test.loc[test['HasOnlineBackup'] == 'No', 'HasOnlineBackup'] = 0
test.loc[test['HasOnlineBackup'] == 'No internet service', 'HasOnlineBackup'] = -1
test['HasOnlineBackup'] = test['HasOnlineBackup'].astype(int)

test.loc[test['HasDeviceProtection'] == 'Yes', 'HasDeviceProtection'] = 1
test.loc[test['HasDeviceProtection'] == 'No', 'HasDeviceProtection'] = 0
test.loc[test['HasDeviceProtection'] == 'No internet service', 'HasDeviceProtection'] = -1
test['HasDeviceProtection'] = test['HasDeviceProtection'].astype(int)

test.loc[test['HasTechSupportAccess'] == 'Yes', 'HasTechSupportAccess'] = 1
test.loc[test['HasTechSupportAccess'] == 'No', 'HasTechSupportAccess'] = 0
test.loc[test['HasTechSupportAccess'] == 'No internet service', 'HasTechSupportAccess'] = -1
test['HasTechSupportAccess'] = test['HasTechSupportAccess'].astype(int)

test.loc[test['HasOnlineTV'] == 'Yes', 'HasOnlineTV'] = 1
test.loc[test['HasOnlineTV'] == 'No', 'HasOnlineTV'] = 0
test.loc[test['HasOnlineTV'] == 'No internet service', 'HasOnlineTV'] = -1
test['HasOnlineTV'] = test['HasOnlineTV'].astype(int)

test.loc[test['HasMovieSubscription'] == 'Yes', 'HasMovieSubscription'] = 1
test.loc[test['HasMovieSubscription'] == 'No', 'HasMovieSubscription'] = 0
test.loc[test['HasMovieSubscription'] == 'No internet service', 'HasMovieSubscription'] = -1
test['HasMovieSubscription'] = test['HasMovieSubscription'].astype(int)

"""Посмотрим на корреляцию численных признаков с целевой переменной."""

corr = data.corr()
corr.style.background_gradient(cmap='coolwarm')

"""# Применение моделей. Вторая часть

Будем использовать две модели: LogisticRegressionCV и RandomForestClassifier (тут будем также использовать GridSearchCV).
"""

from sklearn.linear_model import LogisticRegressionCV
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score
from sklearn.ensemble import RandomForestClassifier

data.info()

num_features = [
    'ClientPeriod',
    'MonthlySpending',
    'TotalSpent',
    'Sex',
    'IsSeniorCitizen',
    'HasPartner',
    'HasChild',
    'HasPhoneService',
    'HasMultiplePhoneNumbers',
    'HasInternetService',
    'HasOnlineSecurityService',
    'HasOnlineBackup',
    'HasDeviceProtection',
    'HasTechSupportAccess',
    'HasOnlineTV',
    'HasMovieSubscription',
    'IsBillingPaperless'
]

cat_features = ['HasContractPhone', 'PaymentMethod']

"""Для модели логистической регрессии переведем все данные в численные значения с помощью one hot encoding."""

dummy_features = pd.get_dummies(data[cat_features])
dummy_features_test = pd.get_dummies(test[cat_features])

X = pd.concat([data[num_features], dummy_features], axis=1)
X.head()

X_test = pd.concat([test[num_features], dummy_features_test], axis=1)

y = data[target_col]

X_train, X_val, y_train, y_val = train_test_split(X.values, y.values, 
                                                    train_size=0.8,
                                                    random_state=42)

"""Также для модели логистической регрессии проведем нормализацию данных."""

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test.values)

lgcv = LogisticRegressionCV(cv=5, scoring='roc_auc', refit=True, random_state=42)

lgcv = lgcv.fit(X_train_scaled, y_train)

preds_train = lgcv.predict_proba(X_train_scaled)[:, 1]
preds_val = lgcv.predict_proba(X_val_scaled)[:, 1]
print("ROC-AUC модели LogisticRegressionCV на обучении:", roc_auc_score(y_train, preds_train))
print("ROC-AUC модели LogisticRegressionCV на валидации:", roc_auc_score(y_val, preds_val))

"""Возьмем несколько параметров для перебора по сетке при применении модели случайного леса."""

parameters = {'criterion': ('gini', 'entropy', 'log_loss'), 
              'max_depth': [1, 5, 10], 
              'n_estimators': [5, 20, 100], 
              'min_samples_split': [2, 5, 8]
              }
rf = RandomForestClassifier()
clf = GridSearchCV(rf, parameters, verbose=1)
clf.fit(X_train_scaled, y_train)
print("Лучшие гиперпараметры:", clf.best_params_)

preds_train = clf.best_estimator_.predict_proba(X_train_scaled)[:, 1]
preds_val = clf.best_estimator_.predict_proba(X_val_scaled)[:, 1]

print("ROC-AUC модели RandomForestClassifier с применение GridSearchCV на обучении:", roc_auc_score(y_train, preds_train))
print("ROC-AUC модели RandomForestClassifier с применение GridSearchCV на валидации:", roc_auc_score(y_val, preds_val))

"""**Лучшего качества удалось добиться на валидационной выборке при использовании модели LogisticRegressionCV - 0.84. При использовании RandomForestClassifier с помощью кросс-валидации параметров качество вышло 0.8396.**

## Применение градиентного бустинга
"""

X_cat = data.drop(columns=['Churn'], axis=1)
y_cat = data['Churn']

X_train_cat, X_val_cat, y_train_cat, y_val_cat = train_test_split(X_cat, y_cat, 
                                                    train_size=0.8,
                                                    random_state=42)

!pip install catboost

!pip install optuna

import optuna
import catboost as cb

# Определите объективную функцию для оптимизации
def objective(trial):
    # Определите пространство поиска для гиперпараметров
    param = {
        'iterations': trial.suggest_int("iterations", 100, 1000),
        'learning_rate': trial.suggest_float("learning_rate", 1e-3, 1e-1, log=True),
        'depth': trial.suggest_int("depth", 4, 10),
        'l2_leaf_reg': trial.suggest_float("l2_leaf_reg", 1e-8, 100.0, log=True),
        'bootstrap_type': trial.suggest_categorical("bootstrap_type", ["Bayesian"]),
        'bagging_temperature': trial.suggest_float("bagging_temperature", 0.0, 10.0),
        'od_type': trial.suggest_categorical("od_type", ["IncToDec", "Iter"]),
        'od_wait': trial.suggest_int("od_wait", 10, 50)
    }

    cat_features = ['HasContractPhone', 'PaymentMethod']

    # Обучить модель, используя заданные гиперпараметры
    model = cb.CatBoostClassifier(**param, cat_features=cat_features)
    model.fit(X_train_cat, y_train_cat, eval_set=(X_val_cat, y_val_cat), early_stopping_rounds=100, verbose=False)

    # Вычислить точность валидации
    valid_pred = model.predict_proba(X_val_cat)[:, 1]
    valid_roc = roc_auc_score(y_val_cat, valid_pred)

    # Возвращаем точность валидации в качестве объективного значения
    return valid_roc

# Создайте объект исследования и оптимизируйте объективную функцию
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100, show_progress_bar=True)

# Выведите наилучшую точность валидации и гиперпараметры
print('Best validation accuracy: {:.3f}'.format(study.best_value))
print('Best hyperparameters: {}'.format(study.best_params))

optimized_classifier = cb.CatBoostClassifier(iterations=study.best_params["iterations"],
                                             learning_rate=study.best_params["learning_rate"],
                                             depth=study.best_params["depth"],
                                             l2_leaf_reg=study.best_params["l2_leaf_reg"],
                                             bootstrap_type=study.best_params["bootstrap_type"],
                                             bagging_temperature=study.best_params["bagging_temperature"],
                                             od_type=study.best_params["od_type"],
                                             od_wait=study.best_params["od_wait"]
                                             )

cat_features = ['HasContractPhone', 'PaymentMethod']

optimized_classifier.fit(X_train_cat, y_train_cat,
                        eval_set=[(X_val_cat, y_val_cat)],
                        early_stopping_rounds=100,
                       cat_features=cat_features,
                       use_best_model=True, silent=True)
pred_valid = optimized_classifier.predict_proba(X_val_cat)[:, 1]
valid_roc = roc_auc_score(y_val_cat, pred_valid)
print("ROC-AUC модели CatBoostClassifier на валидации:", valid_roc)

"""**Лучшее качество удалось получить с помощью градиентного бустинга и библиотеки оптимизации гиперпараметров Optuna при параметрах, которые выведены выше. ROC-AUC = 0.846. Следовательно, лучше всего сработала эта модель среди всех остальных.**

# Предсказания
"""

best_model = optimized_classifier

sample_submission

sample_submission['Churn'] = best_model.predict_proba(test)[:, 1]
sample_submission.to_csv('./my_submission.csv', index=False)

"""В соревновании на Kaggle была получена метрика ROC-AUC = 0.8409."""